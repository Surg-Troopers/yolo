{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099fae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install deps if not already installed (CPU version)\n",
    "# %pip uninstall -y torch torchvision torchaudio\n",
    "# %pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n",
    "\n",
    "# %pip install --upgrade ultralytics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fbbf82",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e25be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, ultralytics\n",
    "from ultralytics import YOLO\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "\n",
    "DEVICE = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device available:\", DEVICE)\n",
    "\n",
    "print(\"Ultralytics:\", ultralytics.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6681c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8m.pt\")\n",
    "results = model.train(\n",
    "    data=\"data.yaml\",\n",
    "    epochs=300,\n",
    "    patience=25,\n",
    "    imgsz=512,         \n",
    "    conf=0.70,\n",
    "    batch=-1,          \n",
    "    device=0,\n",
    "    workers=4,       \n",
    "    lr0=5e-4,\n",
    "    cos_lr=True,\n",
    "    degrees=0.0, # == 0.0\n",
    "    shear=10.0, # == 10.0\n",
    "    translate=0.05, # == 0.05\n",
    "    scale=0.2, # == 0.2\n",
    "    fliplr=0.5,\n",
    "    flipud=0.0,\n",
    "    mosaic=0.2, # == 0.2\n",
    "    mixup=0.0,\n",
    "    close_mosaic=10, # == 10\n",
    "    name=\"yolov8s_the_final_run_wPSeudo\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e66dae3",
   "metadata": {},
   "source": [
    "# Run the code below to run images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef72799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import output_format\n",
    "import extract_frame\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# images_cat1_path = \"data_masked/cat1_test_validation_vid7\"\n",
    "# os.makedirs(images_cat1_path, exist_ok=True)\n",
    "\n",
    "# # --------- extraction zone ----------- #\n",
    "# video_path = \"data/validation/video/7_fps1.mp4\"\n",
    "# # output_dir = \"data_masked/cat1_test_validation_fixed_index\"\n",
    "# output_dir = images_cat1_path\n",
    "# extract_frame.extract_frames(video_path, output_dir)\n",
    "# ------------------------------------- #\n",
    "\n",
    "model = YOLO(\"runs/detect/yolov8s_god20/weights/best.pt\")\n",
    "# video_path = \"/mnt/d/SurgVU 25/surgvu24_videos_only/surgvu24/case_001/case_001_video_part_001.mp4\"\"\n",
    "pred = model.predict(\n",
    "    source=\"/home/kuo/yolo/for_pseudo_ltr_after_mask/8\",\n",
    "    device=DEVICE,\n",
    "    imgsz=512,\n",
    "    max_det = 4,\n",
    "    # iou = 0.4,\n",
    "    conf=0.75, # confidence threshold set to 0.25 temp\n",
    "    save=True,\n",
    "    visualize = False,\n",
    "    # stream=True,\n",
    ")\n",
    "output_format.output_format_as_json(pred)\n",
    "\n",
    "print(\"Saved predictions to:\", pred[0].save_dir if pred else \"n/a\")\n",
    "\n",
    "#####################\n",
    "\n",
    "# Paths\n",
    "output_labels = \"/home/kuo/yolo/for_pseudo_ltr_b4_split/8/labels\"\n",
    "output_images = \"/home/kuo/yolo/for_pseudo_ltr_b4_split/8/images\"\n",
    "\n",
    "# Make sure output dirs exist\n",
    "os.makedirs(output_labels, exist_ok=True)\n",
    "os.makedirs(output_images, exist_ok=True)\n",
    "\n",
    "# Save predictions as YOLO-format txt and copy images\n",
    "for r in pred:\n",
    "    img_path = r.path\n",
    "    name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    label_path = os.path.join(output_labels, f\"{name}.txt\")\n",
    "\n",
    "    # Write predictions\n",
    "    with open(label_path, \"w\") as f:\n",
    "        for box in r.boxes:\n",
    "            cls = int(box.cls)         # class id\n",
    "            conf = float(box.conf)     # confidence\n",
    "            x1, y1, x2, y2 = box.xyxy[0]  # absolute coords\n",
    "\n",
    "            # Convert to YOLO format\n",
    "            x_center = ((x1 + x2) / 2) / r.orig_shape[1]\n",
    "            y_center = ((y1 + y2) / 2) / r.orig_shape[0]\n",
    "            width = (x2 - x1) / r.orig_shape[1]\n",
    "            height = (y2 - y1) / r.orig_shape[0]\n",
    "\n",
    "            if conf > 0.75:  # keep only confident boxes\n",
    "                f.write(f\"{cls} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "\n",
    "    # Check if label file is empty\n",
    "    if os.path.getsize(label_path) == 0:\n",
    "        # No detections → remove label and skip copying image\n",
    "        os.remove(label_path)\n",
    "        print(f\"🗑️ Removed empty label: {label_path}\")\n",
    "    else:\n",
    "        # Only copy image if there was at least one detection\n",
    "        dst_img = os.path.join(output_images, os.path.basename(img_path))\n",
    "        shutil.copy(img_path, dst_img)\n",
    "\n",
    "print(\"✅ Pseudo-labels and images saved (empty ones removed).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ad30a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Paths\n",
    "output_labels = \"Cat1_vid1_frames/pseudo_cat1_vid6/labels\"\n",
    "image_source = \"data_masked/cat1_test_validation_vid6\"\n",
    "output_images = \"Cat1_vid1_frames/pseudo_cat1_vid6/images\"\n",
    "\n",
    "# Make sure output dirs exist\n",
    "os.makedirs(output_labels, exist_ok=True)\n",
    "os.makedirs(output_images, exist_ok=True)\n",
    "\n",
    "# Load model and run inference (assuming pred is already created in your code)\n",
    "# model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
    "# pred = model.predict(source=image_source, conf=0.5)\n",
    "\n",
    "# Save predictions as YOLO-format txt\n",
    "for r in pred:\n",
    "    img_path = r.path\n",
    "    name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    label_path = os.path.join(output_labels, f\"{name}.txt\")\n",
    "\n",
    "    with open(label_path, \"w\") as f:\n",
    "        for box in r.boxes:\n",
    "            cls = int(box.cls)         # class id\n",
    "            conf = float(box.conf)     # confidence\n",
    "            x1, y1, x2, y2 = box.xyxy[0]  # absolute coords\n",
    "\n",
    "            # Convert to YOLO format\n",
    "            x_center = ((x1 + x2) / 2) / r.orig_shape[1]\n",
    "            y_center = ((y1 + y2) / 2) / r.orig_shape[0]\n",
    "            width = (x2 - x1) / r.orig_shape[1]\n",
    "            height = (y2 - y1) / r.orig_shape[0]\n",
    "\n",
    "            if conf > 0.25:  # keep only confident boxes\n",
    "                f.write(f\"{cls} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "\n",
    "# Paths\n",
    "json_gt = \"Cat1_vid1_frames/6_fps1_gc.json\"   # JSON with GT boxes\n",
    "\n",
    "# Load groundtruth JSON\n",
    "with open(json_gt, \"r\") as f:\n",
    "    gt_data = json.load(f)\n",
    "\n",
    "# Build lookup: frame_number -> allowed tool names\n",
    "gt_map = {}\n",
    "for box in gt_data.get(\"boxes\", []):\n",
    "    name = box[\"name\"]  # e.g., slice_nr_45_needle_driver\n",
    "    parts = name.split(\"_\")\n",
    "    frame_num = int(parts[2])  # slice_nr_45 -> 45\n",
    "    tool_name = \"_\".join(parts[3:])\n",
    "    gt_map.setdefault(frame_num, set()).add(tool_name)\n",
    "\n",
    "# Class mapping (YOLO ID → tool name)\n",
    "id2name = [\n",
    "    \"bipolar_forceps\",\n",
    "    \"cadiere_forceps\",\n",
    "    \"clip_applier\",\n",
    "    \"force_bipolar\",\n",
    "    \"grasping_retractor\",\n",
    "    \"monopolar_curved_scissors\",\n",
    "    \"needle_driver\",\n",
    "    \"permanent_cautery_hook_spatula\",\n",
    "    \"prograsp_forceps\",\n",
    "    \"stapler\",\n",
    "    \"tip_up_fenestrated_grasper\",\n",
    "    \"vessel_sealer\",\n",
    "]\n",
    "\n",
    "# Step 2 & 3: check .txt and copy images\n",
    "for file in glob.glob(os.path.join(output_labels, \"*.txt\")):\n",
    "    base_name = os.path.splitext(os.path.basename(file))[0]\n",
    "    # 1. Remove if empty\n",
    "    if os.path.getsize(file) == 0:\n",
    "        # print(base_name)\n",
    "        os.remove(file)\n",
    "        img_file = os.path.join(image_source, base_name + \".jpg\")\n",
    "        # if os.path.exists(img_file):\n",
    "        #     os.remove(img_file)\n",
    "        continue\n",
    "\n",
    "\n",
    "    # 2. Extract frame number from filename: slice_nr_45 -> 45\n",
    "    try:\n",
    "        parts = base_name.split(\"_\")\n",
    "        # print(parts)\n",
    "        frame_num = int(parts[1])\n",
    "        # print(frame_num)\n",
    "    except (IndexError, ValueError):\n",
    "        # print(f\"Skipping {base_name} (bad name)\")\n",
    "        continue\n",
    "\n",
    "    with open(file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    filtered_lines = []\n",
    "    for line in lines:\n",
    "        cls_id = int(line.strip().split()[0])\n",
    "        tool_name = id2name[cls_id]\n",
    "        if tool_name in gt_map.get(frame_num, set()):\n",
    "            filtered_lines.append(line)\n",
    "\n",
    "    if len(filtered_lines) == 0:\n",
    "        # No correct predictions remain → remove .txt and image\n",
    "        os.remove(file)\n",
    "        img_file = os.path.join(image_source, base_name + \".jpg\")\n",
    "        if os.path.exists(img_file):\n",
    "            os.remove(img_file)\n",
    "        continue\n",
    "    else:\n",
    "        # Save filtered txt (overwrite original)\n",
    "        with open(file, \"w\") as f:\n",
    "            f.writelines(filtered_lines)\n",
    "\n",
    "    # Step 4: copy the corresponding image\n",
    "    src_img = os.path.join(image_source, base_name + \".jpg\")\n",
    "    if os.path.exists(src_img):\n",
    "        dst_img = os.path.join(output_images, f\"{base_name}.jpg\")\n",
    "        shutil.copy(src_img, dst_img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3dd68c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b90c7ea7",
   "metadata": {},
   "source": [
    "# MASKING (clean up the black borders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only maks not split -Ball\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "\n",
    "# Mask dimensions\n",
    "LEFT, TOP, RIGHT, BOTTOM = 190, 55, 190, 30\n",
    "\n",
    "def mask_image(in_path: Path, out_path: Path):\n",
    "    im = Image.open(in_path).convert(\"RGB\")\n",
    "    W, H = im.size\n",
    "    draw = ImageDraw.Draw(im)\n",
    "\n",
    "    # Mask top\n",
    "    draw.rectangle([0, 0, W, TOP], fill=(0, 0, 0))\n",
    "    # Mask bottom\n",
    "    draw.rectangle([0, H - BOTTOM, W, H], fill=(0, 0, 0))\n",
    "    # Mask left\n",
    "    draw.rectangle([0, 0, LEFT, H], fill=(0, 0, 0))\n",
    "    # Mask right\n",
    "    draw.rectangle([W - RIGHT, 0, W, H], fill=(0, 0, 0))\n",
    "\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    im.save(out_path, quality=95)\n",
    "\n",
    "for i in range(1, 9):\n",
    "    SRC = Path(f\"/home/kuo/yolo/for_pseudo_ltr/{i}\")   # source folder\n",
    "    DST = Path(f\"/home/kuo/yolo/for_pseudo_ltr_after_mask/{i}\")  # destination folder\n",
    "\n",
    "    # Mask all images recursively from SRC into DST\n",
    "    for img_path in SRC.rglob(\"*.*\"):\n",
    "        if img_path.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "            rel_path = img_path.relative_to(SRC)\n",
    "            out_img = DST / rel_path\n",
    "            mask_image(img_path, out_img)\n",
    "\n",
    "    print(\"✅ Masked dataset created at:\", DST)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306d540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw \n",
    "import shutil \n",
    "\n",
    "SRC = Path(\"/home/kuo/yolo/new_data_sept8_split\")\n",
    "DST = Path(\"/home/kuo/yolo/new_data_sept8_after_mask\")\n",
    "\n",
    "LEFT, TOP, RIGHT, BOTTOM = 190, 55, 190, 30\n",
    "\n",
    "def mask_image(in_path: Path, out_path: Path):\n",
    "    im = Image.open(in_path).convert(\"RGB\")\n",
    "    W, H = im.size\n",
    "    draw = ImageDraw.Draw(im)\n",
    "\n",
    "    # mask top\n",
    "    draw.rectangle([0, 0, W, TOP], fill=(0, 0, 0))\n",
    "    # mask bottom\n",
    "    draw.rectangle([0, H - BOTTOM, W, H], fill=(0, 0, 0))\n",
    "    # mask left\n",
    "    draw.rectangle([0, 0, LEFT, H], fill=(0, 0, 0))\n",
    "    # mask right\n",
    "    draw.rectangle([W - RIGHT, 0, W, H], fill=(0, 0, 0))\n",
    "\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    im.save(out_path, quality=95)\n",
    "\n",
    "# Process train + validation sets\n",
    "for split in [\"train\", \"validation\"]:\n",
    "    img_dir = SRC / split / \"images\"\n",
    "    lbl_dir = SRC / split / \"labels\"\n",
    "    out_img_dir = DST / split / \"images\"\n",
    "    out_lbl_dir = DST / split / \"labels\"\n",
    "    out_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for img_path in img_dir.glob(\"*.*\"):\n",
    "        # out_img = out_img_dir / img_path.name\n",
    "        shutil.copy2(img_path, out_img_dir / img_path.name)\n",
    "        # mask_image(img_path, out_img)\n",
    "\n",
    "        # copy label without change\n",
    "        lbl_path = lbl_dir / (img_path.stem + \".txt\")\n",
    "        if lbl_path.exists():\n",
    "            shutil.copy2(lbl_path, out_lbl_dir / lbl_path.name)\n",
    "\n",
    "print(\"Masked dataset created at:\", DST)\n",
    "print(\"Update data.yaml path to:\", DST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db2c131",
   "metadata": {},
   "source": [
    "# Comparing to Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff96949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def corners_to_xyxy(corners):\n",
    "    \"\"\"Convert 4 corners -> [xmin, ymin, xmax, ymax].\"\"\"\n",
    "    xs = [p[0] for p in corners]\n",
    "    ys = [p[1] for p in corners]\n",
    "    return [min(xs), min(ys), max(xs), max(ys)]\n",
    "\n",
    "def load_boxes(json_file):\n",
    "    \"\"\"Load bounding boxes grouped by slice_nr.\"\"\"\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    results = defaultdict(list)\n",
    "    for box in data[\"boxes\"]:\n",
    "        name = box[\"name\"]  # e.g. slice_nr_45_needle_driver\n",
    "        parts = name.split(\"_\")\n",
    "        frame = int(parts[2])  # 45\n",
    "        label = \"_\".join(parts[3:])  # needle_driver, etc.\n",
    "        coords = corners_to_xyxy(box[\"corners\"])\n",
    "        results[frame].append({\"label\": label, \"bbox\": coords})\n",
    "    return results\n",
    "\n",
    "def iou(box1, box2):\n",
    "    \"\"\"calculate the iou value\"\"\"\n",
    "    # box = [xmin, ymin, xmax, ymax]\n",
    "    xA = max(box1[0], box2[0])\n",
    "    yA = max(box1[1], box2[1])\n",
    "    xB = min(box1[2], box2[2])\n",
    "    yB = min(box1[3], box2[3])\n",
    "\n",
    "    inter = max(0, xB - xA) * max(0, yB - yA)\n",
    "    area1 = (box1[2]-box1[0]) * (box1[3]-box1[1])\n",
    "    area2 = (box2[2]-box2[0]) * (box2[3]-box2[1])\n",
    "    union = area1 + area2 - inter\n",
    "\n",
    "    return inter / union if union > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c503c922",
   "metadata": {},
   "source": [
    "### Compare predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ced4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = load_boxes(\"ground_truth.json\") # some ground_truth file\n",
    "compared_predictions = output_format.output_format_as_json(pred)\n",
    "\n",
    "for frame in ground_truth:\n",
    "    print(f\"\\nFrame {frame}\")\n",
    "    gt_boxes = ground_truth[frame]\n",
    "    pred_boxes = compared_predictions.get(frame, [])\n",
    "    \n",
    "    for g in gt_boxes:\n",
    "        best_iou = 0\n",
    "        best_pred = None\n",
    "        for p in pred_boxes:\n",
    "            if g[\"label\"] == p[\"label\"]:  # same class\n",
    "                print(f\"    class {g[\"label\"]} gt/p:\")\n",
    "                print(f\"      {g[\"bbox\"]}/ {p[\"bbox\"]}\")\n",
    "                score = iou(g[\"bbox\"], p[\"bbox\"])\n",
    "                if score > best_iou:\n",
    "                    best_iou = score\n",
    "                    best_pred = p\n",
    "        print(f\"  GT: {g['label']} {g['bbox']} -> best IoU {best_iou:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
